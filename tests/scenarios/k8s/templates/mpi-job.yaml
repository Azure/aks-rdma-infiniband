{{- if .Values.mpiJob.enabled }}
apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: nccl-tests
  labels:
    app: nccl-tests
spec:
  slotsPerWorker: 8
  runPolicy:
    cleanPodPolicy: {{ .Values.mpiJob.cleanPodPolicy | default "Running" }}
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        metadata:
          {{- if .Values.ipoib }}
          annotations:
            k8s.v1.cni.cncf.io/networks: aks-infiniband
          {{- end }}
          labels:
            app: nccl-tests
        spec:
          restartPolicy: OnFailure
          containers:
          - image: {{ .Values.mpiJob.image }}
            name: nccl
            env:
            - name: OMPI_ALLOW_RUN_AS_ROOT
              value: "1"
            - name: OMPI_ALLOW_RUN_AS_ROOT_CONFIRM
              value: "1"
            - name: NUMBER_OF_PROCESSES
              value: "{{ .Values.mpiJob.numberOfProcesses }}"
            envFrom:
            - configMapRef:
                name: nccl-env-vars
            command:
            - /bin/bash
            - -c
            args:
            - |
              set -xe
              until mpirun -np ${NUMBER_OF_PROCESSES} -x LD_LIBRARY_PATH -bind-to none /usr/bin/nvidia-smi -L 2>/dev/null; do sleep 5; done
              mpirun \
                -np ${NUMBER_OF_PROCESSES} \
                -bind-to none \
                -x NCCL_DEBUG=${NCCL_DEBUG} \
                -x NCCL_DEBUG_SUBSYS=${NCCL_DEBUG_SUBSYS} \
                -x NCCL_IB_DISABLE=${NCCL_IB_DISABLE} \
                -x NCCL_NET_GDR_LEVEL=${NCCL_NET_GDR_LEVEL} \
                -x CUDA_DEVICE_ORDER=PCI_BUS_ID \
                -x NCCL_TOPO_FILE=/opt/nvidia-topology/topo.xml \
                -x NCCL_SOCKET_IFNAME=${NCCL_SOCKET_IFNAME} \
                  /opt/nccl_tests/build/all_reduce_perf \
                    -c 0 \
                    -b 8 \
                    -e 16G \
                    -f 4 \
                    -g 1 \
                    -n 10
            resources:
              requests:
                cpu: 50m
                memory: 128Mi
          enableServiceLinks: false
          automountServiceAccountToken: false
    Worker:
      replicas: 2
      template:
        metadata:
          {{- if .Values.ipoib }}
          annotations:
            k8s.v1.cni.cncf.io/networks: aks-infiniband
          {{- end }}
          labels:
            task: test
        spec:
          {{- if .Values.dranet.enabled }}
          resourceClaims:
          - name: rdma-nic
            resourceClaimTemplateName: {{ .Values.dranet.resourceClaimTemplateName | default "rdma-nic-template" }}
          {{- end }}
          containers:
          - image: {{ .Values.mpiJob.image }}
            name: nccl
            {{- if .Values.resources }}
            resources:
              limits:
                {{- toYaml .Values.resources | nindent 16 }}
              requests:
                {{- toYaml .Values.resources | nindent 16 }}
            {{- end }}
            {{- if .Values.securityContext }}
            securityContext:
              {{- toYaml .Values.securityContext | nindent 14 }}
            {{- end }}
            volumeMounts:
            - name: shm
              mountPath: /dev/shm
            - name: nvidia-topology
              mountPath: /opt/nvidia-topology
          volumes:
          - name: shm
            emptyDir:
              medium: Memory
          - name: nvidia-topology
            configMap:
              name: nvidia-topology
              items:
              - key: topo.xml
                path: topo.xml
          affinity:
            podAntiAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                  - key: task
                    operator: In
                    values:
                    - test
                topologyKey: kubernetes.io/hostname
          enableServiceLinks: false
          automountServiceAccountToken: false
{{- end }}

